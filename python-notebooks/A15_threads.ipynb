{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:red;background-color:black\">\n",
    "Diamond Light Source\n",
    "<br style=\"color:red;background-color:antiquewhite\"><h1>Python Language: Threading</h1>  \n",
    "\n",
    "Â©2000-23 Chris Seddon \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Thread\n",
    "\n",
    "A thread is a separate flow of execution through your code. This means that different threads may be running the \n",
    "same code at different times, but they could be executing entirely different code.\n",
    "\n",
    "Threads are used when you want to run multiple sections of code concurrently.  In most programming languages, \n",
    "threads can be run on different CPUs to achieve true concurrency, but often time slicing on the same CPU is used \n",
    "to create apparent concurrency.  When multiple CPUs are used, threading can greatly speed up code.\n",
    "\n",
    "Most Python programs are run using CPython which is the default implementation of Python.  CPython was originally\n",
    "written when single threaded programs were the norm and it was felt that making CPython thread safe (see later\n",
    "for what that really means) would slow down existing programs.  To avoid contentions between threads, CPython creates a Global Interface Lock (GIL) \n",
    "each time a thread is run, effectively serialising threaded code.  Although this avoids errors it also creates\n",
    "a performance bottleneck; we will look at the GIL in subsequent examples.  Many attempts have been made to make \n",
    "CPython thread safe, but political arguments have so far stopped this from happening.\n",
    "\n",
    "In practice, threading is still useful for concurrent tasks, but your code won't necessarily run faster.  IO-bound \n",
    "tasks spend a lot of time waiting (idle) for data to be ready.  For these tasks there is a real speed benefit, by \n",
    "switching to running code in another thread, when the the current thread becomes I/O bound.  However, for CPU-bound\n",
    "tasks, switching threads won't speed things up because no threads are in an idle state.\n",
    "\n",
    "CPython has always been single threaded and it is highly unlikely that this will ever change.  PyPy is the other \n",
    "popular implementation of Python, but that too has a GIL.  The good news is that code that uses libraries written in\n",
    "C/C++ such as Numpy don't use the GIL and can use threading for CPU-bound tasks.\n",
    "\n",
    "If you want to run concurrent CPU-bound Python code, you should check out the multiprocessing module instead.\n",
    "This gets around the problem of using the GIL by creating separate python interpreters, one for each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Creating Threads\n",
    "Recall that threads are used to perform concurrent tasks.  Threads are ultimately created by the operating system (kernel), but as far as we are concerned we make a Python call to start a thread; the Python interpreter then contacts the kernel.\n",
    "\n",
    "Python provides a helper class to manage threads.  Rather confusingly, this class is called \"Thread\".  Objects of this class are NOT threads, just helper objects!\n",
    "\n",
    "All programs start with a single thread (often called the main thread).  When the main thread wants to create further threads, it creates objects of the helper class and calls their \"start\" method:<pre>thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()</pre>\n",
    "\n",
    "Realize that when the new threads start, they need to perform a different task (or function) from the main thread.  This task is specified as a parameter when the main thread creates the helper objects:<pre>thread1 = Thread(target=myfunc, args=(\"1\",))\n",
    "thread2 = Thread(target=myfunc, args=(\"2\",))\n",
    "thread3 = Thread(target=myfunc, args=(\"3\",))</pre>\n",
    "Creating the helper objects DOES NOT create any threads - calling the start method creates and starts a thread.\n",
    "\n",
    "After the \"start\" method has been called, execution of the main thread and the other threads continues in parallel.  Because the operating system may suspend threads at any time, it is not possible to predict which order code will execute unless we use special synchronization objects.\n",
    "\n",
    "In this example the main thread creates 3 other threads which all execute the \"myfunc\" function.  Each of these threads terminate when they exit this function.  I've added some random timings to emphasize the parallel nature of this program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "def myfunc(name):\n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)        \n",
    "        time.sleep(random.random() * 0.1)      \n",
    "\n",
    "# define a callback function - to be called via start()\n",
    "thread1 = Thread(target=myfunc, args=(\"1\",))\n",
    "thread2 = Thread(target=myfunc, args=(\"2\",))\n",
    "thread3 = Thread(target=myfunc, args=(\"3\",))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "print(\"\\nEnd of main Thread\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Joining Threads\n",
    "Note that the main thread is counted a just another thread (it is not special).  However, often programs are designed such that the main thread is the last to complete.  To achieve this, the main thread can wait for the other threads to complete before proceding:<pre>thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from threading import Thread\n",
    "\n",
    "def myfunc(name):\n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)        \n",
    "        time.sleep(random.random() * 0.1)      \n",
    "\n",
    "# define a callback function - to be called via start()\n",
    "thread1 = Thread(target=myfunc, args=(\"1\",))\n",
    "thread2 = Thread(target=myfunc, args=(\"2\",))\n",
    "thread3 = Thread(target=myfunc, args=(\"3\",))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "\n",
    "print(\"\\nEnd of main Thread\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Using Methods as Callbacks\n",
    "As an alternative to specifying the target function for a thread, we can make the callback function a method in a \n",
    "class; this ultimately depends on operator overloading.  In the previous example the callback function was \"myfunc\" \n",
    "and after the \"start\" method is called, Python calls back on this function.\n",
    "\n",
    "We can equally specify an object as a callback.  Python will try to call this object; i.e. call the overloaded\n",
    "() for the class.  Thus if the target is the object \"m1\" \n",
    "<pre>            t1 = Thread(target = m1, args = (\"1\",))\n",
    "</pre>\n",
    "the callback will be on:\n",
    "<pre>            m1()\n",
    "</pre>            \n",
    "and because of operator overloading, this is equivalent to calling the dunder method:\n",
    "<pre>            m1.__call__()\n",
    "</pre>\n",
    "So you can use an object as the target provided it's class has a \"__call__()\" method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# create a callable class\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, name):\n",
    "        for i in range (1, 50):\n",
    "            sys.stdout.write(name)        \n",
    "            time.sleep(random.random() * 0.1)    \n",
    "\n",
    "    \n",
    "m1 = MyClass()\n",
    "m2 = MyClass()\n",
    "m3 = MyClass()\n",
    "\n",
    "# define a callback class - __call__() to be called via start()\n",
    "t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Locks\n",
    "To control parallel threads we can use synchronization classes.  The most import is the \"Lock\" class.  A \"Lock\" \n",
    "object will allow only one thread at a time execute the code guarded by the lock.  A thread acquires a lock with:\n",
    "<pre>           lock.acquire()</pre>\n",
    "\n",
    "and releases a lock with \n",
    "<pre>           lock.release()</pre>\n",
    "\n",
    "The code between these calls is guarded.  Such locks are often called monitor locks; they monitor code and only \n",
    "allow one thread at a time execute code between the \"acquire\" and \"release\" calls.\n",
    "\n",
    "In this example, 4 threads execute code in the \"\\_\\_call\\_\\_\" method, but the monitor lock (`lock3`) serializes execution.  \n",
    "\n",
    "If you try using two or more locks you will find threads sharing the same lock do not execute concurrently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Lock\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# task for threads\n",
    "def task(name, lock):\n",
    "    lock.acquire()        \n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)\n",
    "        time.sleep(random.random() * 0.1)\n",
    "    lock.release()    \n",
    "\n",
    "    \n",
    "lock = Lock()\n",
    "\n",
    "t1 = Thread(target = task, args = (\"1\", lock))\n",
    "t2 = Thread(target = task, args = (\"2\", lock))\n",
    "t3 = Thread(target = task, args = (\"3\", lock))\n",
    "t4 = Thread(target = task, args = (\"4\", lock))\n",
    "\n",
    "# create 4 threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Locks\n",
    "If we modify the example slightly and create 2 locks, one lock shared by threads 1 and 3 and the other by threads 2 and 4 then the locks will prevent 1 and 3 running simultaneously and similarly with 2 and 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Lock\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "# task for threads\n",
    "def task(name, lock):\n",
    "    lock.acquire()        \n",
    "    for i in range (1, 50):\n",
    "        sys.stdout.write(name)\n",
    "        time.sleep(random.random() * 0.1)\n",
    "    lock.release()    \n",
    "\n",
    "    \n",
    "lockA = Lock()\n",
    "lockB = Lock()\n",
    "\n",
    "t1 = Thread(target = task, args = (\"1\", lockA))\n",
    "t2 = Thread(target = task, args = (\"2\", lockB))\n",
    "t3 = Thread(target = task, args = (\"3\", lockA))\n",
    "t4 = Thread(target = task, args = (\"4\", lockB))\n",
    "\n",
    "# create 4 threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Sharing Data\n",
    "As discussed previously, code using += is not thread safe.  As an illustration of this we define two counts and\n",
    "then increment these counts in 3 separate threads.  One of the counts is protected by a lock, but the other is not.\n",
    "We have to increment many (10 million) times to maximise the chance of being suspended in the critical section of \n",
    "code.  The protected count will always end up at 3 threads x 10 million = 30,000,000, but the other count will\n",
    "usually end up less as a result of the contention between the threads.\n",
    "\n",
    "Because programmers are prone to forget to release locks, we give alternate ways of using a lock in threads \"B\"\n",
    "and \"C\".  Thread \"B\" uses a finally block and thread \"C\" uses a with statement.  The with statement is expanded\n",
    "by the interpreter to the try-finally form (so these forms are equivalent).\n",
    "\n",
    "Note that often code is modified after the initial design and we might introduce code that could throw an exception\n",
    "between obtaining the lock and releasing it.  That's why it's better to use the with statement than the straight\n",
    "lock.release() because \"with\" is exception safe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from threading import Lock\n",
    "\n",
    "# 3 threads increment 2 Counters ...\n",
    "# count1 is unprotected\n",
    "# count2 is protected\n",
    "\n",
    "N = 10*1000*1000\n",
    "\n",
    "class M:\n",
    "    lock = Lock()\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "\n",
    "    def __call__(self, name):        \n",
    "        if name == \"A\":\n",
    "            for i in range(0, N):\n",
    "                M.count1 += 1\n",
    "            M.lock.acquire()\n",
    "            for i in range(0, N):\n",
    "                M.count2 += 1\n",
    "            M.lock.release()\n",
    "        if name == \"B\":\n",
    "            for i in range(0, N):\n",
    "                M.count1 += 1\n",
    "            M.lock.acquire()\n",
    "            try:\n",
    "                for i in range(0, N):\n",
    "                    M.count2 += 1\n",
    "            finally:\n",
    "                M.lock.release()\n",
    "        if name == \"C\":\n",
    "            M.count1 += 1\n",
    "            with M.lock:\n",
    "                for i in range(0, N):\n",
    "                    M.count2 += 1\n",
    "\n",
    "m1 = M()\n",
    "m2 = M()\n",
    "m3 = M()\n",
    "\n",
    "t1 = Thread(target = m1, args = (\"A\",))\n",
    "t2 = Thread(target = m2, args = (\"B\",))\n",
    "t3 = Thread(target = m3, args = (\"C\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(\"\")\n",
    "print(f\"M.count1: {M.count1}\")\n",
    "print(f\"M.count2: {M.count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Data Corruption\n",
    "The data corruption occurs because:<pre>\n",
    "    count1 += 1</pre>\n",
    "is not an atomic operation.  We can see this by examining the byte code using the disassembler module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "dis.dis(\"x += 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Atomic Instructions\n",
    "What can happen is that the thread can get suspended by the kernel just after the INPLACE_ADD instruction.  \n",
    "\n",
    "Suppose \"x\" is some value, say 700.  Inside the interpreter, the INPLACE_ADD will add 1 to 700 and store 701 in a machine register.  If the thread then gets suspended, this register will be cached by the kernel.  \n",
    "\n",
    "Other threads will now increment \"x\" many times.  Let's say \"x\" ends up with the value 3287 for sake of argument.\n",
    "\n",
    "Eventually, the original thread will be restarted.  Its registers will be reinstated by the kernel, so it can continue where it left off.  The thread was just about to execute the STORE_NAME instruction; when it does execute the instruction it uses the value 701 from the reinstated register.  This overwrites 3287 with 701, thereby corrupting the count.  That's what happened above.\n",
    "\n",
    "Conclusion: all non-atomic operations need protecting by locks.\n",
    "\n",
    "But how do we know if an operation is atomic?  Take a look at the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "dis.dis(\"[2,5,3,6].sort()\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Global Interpreter Lock (GIL)\n",
    "In the above, the \"sort\" method is executed as a single byte code instruction CALL_METHOD.  This is what makes it atomic.  The Python interpreter cannot suspend a thread part way through a byte code instruction.\n",
    "\n",
    "The GIL is a lock held by CPython interpreter whenever bytecode is being executed unless it is explicitly released \n",
    "by the programmer.  CPython assumes that whatever occurs between bytecodes is not thread-safe unless told otherwise.\n",
    "This implies that the GIL is enabled by default.  CPython releases the GIL periodically to allow other threads to\n",
    "run.\n",
    "\n",
    "Other implementation of the Python interpreter such as Jython and IronPython have no GIL and can fully exploit \n",
    "multithreading.  PyPy currently has a GIL (similar to CPython) and Cython also has a GIL.  Note, the GIL in Cython \n",
    "can be released temporarily using a \"with\" statement. \n",
    "\n",
    "In CPython, the GIL is released every few (<10) msec after completing a byte code instruction.  Operations \n",
    "consisting of a single byte code instruction are atomic and hence thread safe.\n",
    "\n",
    "A thread may release the GIL voluntarily to allow another thread to run.  A thread only needs to hold the GIL \n",
    "while it works with Python objects, so CPython will release the GIL and allow another thread to run if the thread\n",
    "holding the GIL performs I/O operations or other blocking calls into the OS like select() and pthread_mutex_lock().\n",
    "The GIL may also be released by library code written in C/C++.  Note that there is no direct way of releasing the \n",
    "GIL in Python code (but there is if you are writing a C/C++ extension).\n",
    "\n",
    "The instruction:\n",
    "<pre>           count1 += 1</pre>\n",
    "was several byte code instructions and therefore was non-atomic.\n",
    "\n",
    "So operations consisting of a single byte code are thread safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Condition Variables\n",
    "\n",
    "Apart from locks, there are some other synchronization primatives to consider.  Let's now look at the producer/consumer code below.  The problem we have here is that the producer will create data for each of the consumers, but it might take some time to do so.  It is important that the consumers don't attempt to use the data before it is available.\n",
    "\n",
    "We can use a \"condition\" variable to synchronize the threads:\n",
    "<pre>           dataAvailable = threading.Condition()</pre>\n",
    "The consumers all wait on the \"condition\" variable:\n",
    "<pre>           dataAvailable.wait()</pre>\n",
    "until the producer is ready to provide the data.  The producer notifies all the consumers that they can proceed with:\n",
    "<pre>           dataAvailable.notifyAll()</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from threading import Thread\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "class Producer:\n",
    "    def __call__(self, dataAvailable):\n",
    "        print(\"Producer is obtaining data\")\n",
    "        time.sleep(5)\n",
    "        with dataAvailable:         # grab the lock\n",
    "            print(\"Producer is notifying all consumers\")\n",
    "            dataAvailable.notifyAll()\n",
    "\n",
    "class Consumer:\n",
    "    def __call__(self, name, dataAvailable):\n",
    "        with dataAvailable:\n",
    "            print(f\"consumer{name} is waiting\")\n",
    "            dataAvailable.wait()\n",
    "            print(f\"consumer{name} is has obtained the data\")\n",
    "\n",
    "    \n",
    "dataAvailable = threading.Condition()\n",
    "\n",
    "producer = Producer()\n",
    "consumer1 = Consumer()\n",
    "consumer2 = Consumer()\n",
    "consumer3 = Consumer()\n",
    "\n",
    "# give each thread a lock\n",
    "t = Thread(target = producer, args = (dataAvailable,))\n",
    "t1 = Thread(target = consumer1, args = (\"1\", dataAvailable))\n",
    "t2 = Thread(target = consumer2, args = (\"2\", dataAvailable))\n",
    "t3 = Thread(target = consumer3, args = (\"3\", dataAvailable))\n",
    "\n",
    "t.start()\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t.join()\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Events\n",
    "Event objects are very similar to condition variables.  \n",
    "\n",
    "The event object is created by:\n",
    "<pre>           event = Event()</pre>\n",
    "and any thread can wait on the event:\n",
    "<pre>           event.wait()</pre>\n",
    "All waiting threads are released when any thread \"sets\" the event:\n",
    "<pre>           event.set()</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from threading import Event\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class MyClass:\n",
    "    def __call__(self, name):\n",
    "        global event\n",
    "        print(f\"{name} waiting for event\");\n",
    "        event.wait()\n",
    "        print(f\"\\t{name} proceeding after event\");\n",
    "\n",
    "\n",
    "event = Event()\n",
    "\n",
    "m1 = MyClass()\n",
    "m2 = MyClass()\n",
    "m3 = MyClass()\n",
    "\n",
    "t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "print(\"... main waiting for 15 seconds\")\n",
    "time.sleep(15)\n",
    "print(\"... main clearing event flag\")\n",
    "event.set()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Bounded Semaphores\n",
    "Bounded semaphores are like a set of multiple locks.  A bounded semaphore is created with an initial count:\n",
    "<pre>           semaphore = BoundedSemaphore(3)</pre>\n",
    "\n",
    "Threads can acquire the semaphore by decrementing the count:\n",
    "<pre>           semaphore.acquire()</pre>\n",
    "\n",
    "However the count can never go negative.  So after 3 threads have acquired the semaphore the next thread will be blocked until another thread releases the semaphore and increments the count by one:\n",
    "<pre>           semaphore.release()</pre>\n",
    "\n",
    "This continues until all the threads have acquired and released the semaphore.  Thus this bounded semaphore behaves as a set of 3 locks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from threading import BoundedSemaphore\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class MyClass:\n",
    "    def __call__(self, name):\n",
    "        global semaphore\n",
    "        semaphore.acquire()\n",
    "        print((name + \" claimed semaphore\"));\n",
    "        time.sleep(5)\n",
    "        print((\"\\t\" + name + \" released semaphore\"));\n",
    "        semaphore.release()\n",
    "\n",
    "\n",
    "\n",
    "semaphore = BoundedSemaphore(3)\n",
    "\n",
    "m1 = MyClass()\n",
    "m2 = MyClass()\n",
    "m3 = MyClass()\n",
    "m4 = MyClass()\n",
    "m5 = MyClass()\n",
    "m6 = MyClass()\n",
    "m7 = MyClass()\n",
    "\n",
    "t1 = Thread(target = m1, args = (\"1\",))\n",
    "t2 = Thread(target = m2, args = (\"2\",))\n",
    "t3 = Thread(target = m3, args = (\"3\",))\n",
    "t4 = Thread(target = m4, args = (\"4\",))\n",
    "t5 = Thread(target = m5, args = (\"5\",))\n",
    "t6 = Thread(target = m6, args = (\"6\",))\n",
    "t7 = Thread(target = m7, args = (\"7\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "t6.start()\n",
    "t7.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "t6.join()\n",
    "t7.join()\n",
    "\n",
    "print(\"\\nEnd of main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Barriers\n",
    "Barriers are yet another synchronization object.  A barrier is created with a count and a timeout:\n",
    "<pre>           b = Barrier(5, timeout=10)</pre>\n",
    "\n",
    "In this example a server and 4 clients synchronize by waiting on this barrier in their respective threads:\n",
    "<pre>           b.wait()</pre>\n",
    "\n",
    "When all five threads are waiting, the barrier is satisfied and the Python interpreter removes the barrier and all 5 threads continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Barrier\n",
    "import time\n",
    "\n",
    "\n",
    "# In this example a server a 4 clients synchronize by waiting on a barrier\n",
    "# in their respective threads.  When all five threads are waiting, \n",
    "# the barrier is removed and all 5 threads continue.\n",
    "\n",
    "b = Barrier(5, timeout=10)\n",
    "\n",
    "class Server:\n",
    "    def __init__(self):\n",
    "        print(\"server initializing ...\")\n",
    "        self.thread = Thread(target=self)\n",
    "        self.thread.start()\n",
    "\n",
    "    def __call__(self):\n",
    "        time.sleep(5)\n",
    "        b.wait()\n",
    "        print(\"server ready to accept connections\")\n",
    "        \n",
    "    def connect(self, client):\n",
    "        print(f\"{client.name} has connected\")\n",
    "        \n",
    "class Client:\n",
    "    def __init__(self, name, server):\n",
    "        self.name = name\n",
    "        self.server = server\n",
    "        print(f\"{self.name} waiting to connect\")\n",
    "        self.thread = Thread(target=self)\n",
    "        self.thread.start()\n",
    "    \n",
    "    def __call__(self):\n",
    "        b.wait()\n",
    "        self.server.connect(self)\n",
    "\n",
    "def main():\n",
    "    server = Server()\n",
    "    client1 = Client(\"client1\", server)\n",
    "    client2 = Client(\"client2\", server)\n",
    "    client3 = Client(\"client3\", server)\n",
    "    client4 = Client(\"client4\", server)\n",
    "    \n",
    "    server.thread.join()\n",
    "    client1.thread.join()\n",
    "    client2.thread.join()\n",
    "    client3.thread.join()\n",
    "    client4.thread.join()\n",
    "    \n",
    "    print(\"end of program\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 Timers\n",
    "I should mention the simple Timer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Timer\n",
    "\n",
    "def hello():\n",
    "    print(\"hello, world\")\n",
    "\n",
    "t = Timer(15.0, hello)\n",
    "t.start() # after 15 seconds, \"hello, world\" will be printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 Benchmarking\n",
    "Finally, as mentioned in the introduction to this tutorial, with multi threaded CPU-bound programs, the threads are executed sequentially because of the GIL.  Performance then becomes an issue.\n",
    "\n",
    "It is recommended to use the multiprocessing module to speed things up in such situations.  We don't use threads in this case, but execute code in separate processes such that the GIL is irrelevant.\n",
    "\n",
    "It will be interesting to compare a multthreaded program with a mutiprocessing program for timings.  Both programs calculate the value of  \n",
    "\n",
    "$$\\sum i^{0.3}$$  \n",
    "where i ranges from 0 to 50,000,000.  We can see the performance of both with varying numbers of threads and processes (don't worry to much about the code details):\n",
    "\n",
    "Conclusion: threads do not speed up cpu bound calculations; use multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "from threading import Thread\n",
    "from multiprocessing import Process, Pool\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "''' Calculate the sum of i**0.3 where i ranges from 0 to M\n",
    "    Use multiple threads or processes to perform the calculation\n",
    "    Split the calculation into ranges using the intervals function below\n",
    "'''\n",
    "\n",
    "M = 50*1000*1000\n",
    "\n",
    "def calculate(lo, hi):\n",
    "    '''the calculation to perform'''\n",
    "    sum = 0\n",
    "    for i in range (lo, hi):\n",
    "        sum += float(i)**0.3\n",
    "    return sum   \n",
    "\n",
    "def intervals(duration, parts):\n",
    "    '''splits an interval into several(part) ranges'''\n",
    "    part_duration = int(duration / parts)\n",
    "    return [(int(i * part_duration), int((i + 1) * part_duration)) for i in range(parts)]\n",
    "\n",
    "# calculate the sum using multiple threads\n",
    "def jobUsingThreads(threadCount):\n",
    "    threadList = []\n",
    "    it = intervals(M, threadCount)\n",
    "    \n",
    "    for i in range(threadCount):\n",
    "        t = Thread(target = calculate, args = it[i])\n",
    "        t.start()\n",
    "        threadList.append(t)\n",
    "        \n",
    "    for t in threadList:\n",
    "        t.join()\n",
    "\n",
    "# calculate the sum using multiple threads\n",
    "def jobUsingProcesses(processCount):\n",
    "    p = Pool(processes=processCount)\n",
    "    it = intervals(M, processCount)\n",
    "    result = p.starmap(calculate, it)\n",
    "\n",
    "# run job with varying number of processes\n",
    "for N in chain(range(1, 11), range(20, 101, 20)):\n",
    "    start = time.perf_counter()\n",
    "    jobUsingProcesses(N)\n",
    "    finish = time.perf_counter()\n",
    "    print(f\"{N:2} processes:{finish-start:6.2f}\")\n",
    "\n",
    "# run job with varying number of processes\n",
    "for N in chain(range(1, 11), range(20, 101, 20)):\n",
    "    start = time.perf_counter()\n",
    "    jobUsingThreads(N)\n",
    "    finish = time.perf_counter()\n",
    "    print(f\"{N:2} threads:{finish-start:6.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "080ecc9f5a07788699440df6a82f433dff8c2b9abdb7c7a66d09492f06ed7fcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
